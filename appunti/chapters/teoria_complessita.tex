\section{Ripasso}

Si ricordano le definizioni di algoritmo e problema computazionale astratto:

\begin{definition}[Algoritmo]\label{def:alg}
    Un algoritmo è una procedura computazionale finita (terminante) e deterministica, specificata come una sequenza di passi elementari (istruzioni) estratte da un insieme standard associato a un modello computazionale (astrazione di un computer) che trasforma in maniera univoca un ingresso in un uscita.
\end{definition}


\begin{definition}[Problema computazionale]\label{def:probcomp}
    Un problema computazionale $\bpi{}$ è una relazione tra un insieme di istanze $\bi{}$ e un insieme di soluzioni $\bs{}$: $\bpi{} \subseteq \bi{} \times \bs{}$
    \\
    Un problema computazionale definisce la specifica astratta. % ma de che?
\end{definition}

Note:
% \begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
\begin{itemize}[noitemsep,parsep=0pt,partopsep=0pt,topsep=0pt]
    \item[--] le seguenti notazioni sono usate in maniera equivalente: $i_1 \bpi{} s_1 \iff (i_1 , s_1 ) \in \bpi{}$
    \item[--] la relazione non è univoca, ad un'istanza possono essere associate più soluzioni
    \item[--] nella specifica astratta si assume esistano le soluzioni per ogni istanza:\\
        $\forall i \in \bi{},\exists s \in \bs{} | i \bpi{} s$
\end{itemize}

Un algoritmo $A_{\bpi{}}$ è un algoritmo per $\bpi{}$, ossia risolve $\bpi{}$ se, quando i suoi ingressi sono elementi di $\bi{}$, le sue uscite sono gli elementi di $\bs{}$ in relazione all'ingresso, formalmente:
$$ A: \bi{} \to \bs{} \quad \textrm{e} \quad A(i)=s \iff i \, \bpi{} \, s $$

\section{Categorie di problemi}
I problemi computazionali si possono dividere in quattro categorie:

\subsubsection{Polinomiali}
Problemi $\bpi{}$ che ammettono algoritmi di risoluzione polinomiale, che si possono considerare ``facili''. Si trova una certa evidenza epistemiologica che i gradi in generale sono bassi, e si può considerare un problema polinomiale come trattabile.

\subsubsection{Con limite inferiore esponenziale}
Problemi $\bpi{}$ per cui si può provare che la complessità di ogni algoritmo che li risolve è esponenziale.
\begin{equation*}
    \forall A_{\bpi{}} \; \exists \, c > 1 : T_{A_{\bpi{}}} \left( n \right) = \Omega \left( c^{n} \right)
    % \label{}
\end{equation*}
I problemi per cui si riesce a dimostrare questa proprietà sono però molto pochi, in genere problemi artificiali legati ai linguaggi.

\subsubsection{Problemi che non ammettono algoritmi di risoluzione}
Ricordiamo che un algoritmo è una procedura \textit{terminante}. Per esempio l'\textit{halting problem}, si definisce come:
\begin{equation*}
    \bi{}_{H} = \left\{ <MT,x> \right\}
    \;\;
    \bs{}_{H} = \left\{ \texttt{Sì, No} \right\}
\end{equation*}

TODO mancano pezzi


\subsubsection{Problemi intrattabili}

Sono problemi per cui non esiste né un algoritmo $A_{\bpi{}}$ che li risolva, e neppure un \textit{lower bound} esponenziale.
Tuttavia c'è forte evidenza che il \textit{lower bound} esista, infatti si può provare che tutti i problemi in questa classe sono equivalenti, e questa proprietà di chiusura spinge verso la loro difficoltà.

\section{Problemi Decisionali}
% pag 4.2

\subsection{Problemi di ottimizzazione}
% pag 5

In un problema di ottimizzazione, si definisce una funzione di costo associato ad una soluzione:
\begin{equation*}
    c : \bs{} \to \mathbb{R}
\end{equation*}
e, dato l'insieme di soluzioni ammissibili associate ad un'istanza
\begin{equation*}
    \bs{} (i) = \left\{ s \in \bs{} : i \, \bpi{} \, s \right\}
\end{equation*}
si vuole individuare la soluzione di costo massimo (o minimo)
\begin{equation*}
    s_{i}^{*} = \argmax \left\{ c(s) : s \in \bs{} (i) \right\}
\end{equation*}

\subsection{Problemi Decisionali}
% pag 4.2

Per definire problemi e complessità degli algoritmi in modo rigoroso è necessario standardizzare i problemi computazionali.

Un problema decisionale presenta un insieme delle soluzioni ridotto a due elementi, ed associa ad un'istanza generica una risposta (positiva o negativa) ad una domanda sull'istanza.
\begin{equation*}
    \bpi{}_{D} : \bi{} \to \left\{ \texttt{Sì, No} \right\}
\end{equation*}

\subsubsection{\textit{Shortest Unweighted Path}}
% pag 4.5
% Il problema è definito sull'istanza $<G=(V,E), s, t>$, dove $V \subseteq \mathbb{N}$ finito (i nodi sono identificati con numeri naturali), $E \subseteq V \times V$ (gli archi sono coppie ordinate di vertici), $s, t \in V$. L'insieme delle soluzioni è $\mathbb{N}^*$, e una soluzione generica è $s=<v_1, \dots, v_k$, dove $v_i \in V, v_1=s, v_k=t$ e $\left( v_i, v_{i+1} \right) \in E, 1 \leq i < k$.
La restrizione ad un insieme binario di soluzioni non comporta una perdita di generalità, per esempio, si consideri il problema di trovare un cammino minimo tra due nodi in un grafo:
\begin{align*}
    \text{istanza:} \quad & <G=(V,E), s, t> \\
    \text{dove} \quad & V \subseteq \mathbb{N} \quad \text{finito (i nodi sono identificati con numeri naturali)} \\
    & E \subseteq V \times V \quad \text{(gli archi sono coppie ordinate di vertici)} \\
    & s, t \in V \\
    \text{soluzioni:} \quad & s=<v_1, \dots, v_k> \in \mathbb{N}^* \\
    i \, \bpi{} s \text{ se } \quad & 
    % \text{dove} \quad &
    v_i \in V \\
    & v_1=s, \: v_k=t \\
    & \left( v_i, v_{i+1} \right) \in E, 1 \leq i < k \\
    i \, \bpi{} \, \varepsilon \text{ se } \quad & \text{non esiste cammino tra $s$ e $t$ in $G$} \\
    \text{costo:} \quad & c\left( < v_1, \ldots, v_k > \right) = k-1 \\
    & c( \varepsilon ) = \infty \\
    \intertext{A questo problema di ottimizzazione si può associare un problema decisionale, arricchendo l'istanza con un limite superiore alla lunghezza del cammino}
    \text{istanza:} \quad & <G=(V,E), s, t, k> \\
    \text{domanda:} \quad & \text{esiste un cammino tra $s$ e $t$ in $G$, di lunghezza $\leq k$?} \\
\end{align*}
Avendo un algoritmo $A_{KUP}$ che risolva il problema decisionale, si può costruire facilmente un algoritmo che risolva $SUP$, usando $KUP$ come subroutine; l'algoritmo termina, perché si stanno cercando cammini semplici, quindi di lunghezza massima pari al numero di nodi meno uno.
\begin{algorithm}[H]
\caption{Shortest Unweighted Path}\label{alg:sup}
\begin{algorithmic}[1]
    \Procedure{$A_{SUP}$}{$<G=(V,E), s, t>$}
        \State $m \gets |V|$
        \For{$k \gets 0 $ to $ m-1 $ }
        \If{\Call{$A_{KUP}$}{$<G=(V,E), s, t, k>$} = \texttt{Sì}}
                \State return $k$
            \EndIf
        \EndFor
        \State return $\infty$
    \EndProcedure
\end{algorithmic}
\end{algorithm}
Per quanto riguarda la complessità, si possono considerare le due istanze come di taglia paragonabile
\begin{equation*}
    |<G, s, t, k>| = \Theta \left( |<G, s, t>| \right)
\end{equation*}
e assumendo $KUP$ polinomiale
\begin{equation*}
    T_{KUP} = O \left( |<G, s, t, k>|^{h} \right)
\end{equation*}
e considerando che il numero di archi è limitato dalla taglia dell'istanza
\begin{equation}
    m = O \left( |<G, s, t>| \right)
    \label{eq:tagliamgst}
\end{equation}
si ottiene che
\begin{align*}
    T_{SUP} \left( |<G, s, t>| \right) &= O \left( |<G, s, t>||<G, s, t>|^{h} \right) \\
    &= O \left( |<G, s, t>|^{h+1} \right)
\end{align*}
per cui se si riesce a risolvere il problema decisionale si può risolvere anche il problema di ottimizzazione.

Per ESERCIZIO, si scriva un algoritmo che ritorni anche il cammino minimo. Si suggerisce, dopo aver identificato $k$, di rimuovere archi per identificare quali siano quelli necessari per il cammino cercato. La complessità può risultare di due gradi superiore a quella di $KUP$.

\section{Codifica delle istanze}
% pag 6.7
Un problema astratto generico è definito quindi come
\begin{equation*}
    \bpi{}_{A} : \bi{} \to \left\{ \texttt{Sì, No} \right\}
\end{equation*}
Come si evidenzia nell'equazione \ref{eq:tagliamgst}, c'è un forte legame tra taglia dell'istanza e complessità dell'algoritmo. Va quindi definito precisamente il concetto di codifica di un'istanza.
\begin{definition}[\textit{Encoding} (codifica)]\label{def:codifica}
L'\textit{encoding} è una funzione invertibile (iniettiva)
\begin{equation*}
    e : \bi{} \to \left\{ 0,1 \right\}^{*}
\end{equation*}
che mappa istanze in stringhe finite (quindi considera istanze numerabili, che è ragionevole). La notazione completa è $e_{\bi{}}$ per indicare che la codifica è legata ad un preciso insieme di istanze, ma il pedice viene omesso per leggibilità.
\end{definition}

Il problema astratto viene mappato nel problema concreto
\begin{equation*}
    \bpi{}_{C} : \left\{ 0,1 \right\}^{*} \to \left\{ 0,1 \right\}
\end{equation*}
specificato come
\begin{equation*}
    \forall x \in \left\{ 0,1 \right\}^{*} \quad
    \bpi{}_{C} (x) =
    \begin{cases}
        1 & \exists i \, \in \bi{} : e(i) = x \wedge \bpi{}_{A} (i) = \texttt{Sì} \\
        0 & \text{altrimenti}
    \end{cases}
\end{equation*}
Va notato che il problema concreto associa il valore $0$ sia ad istanze correttamente formate con risposta negativa, sia a tutte le stringhe non associate ad un'istanza.

Il problema concreto corrisponde ad un linguaggio formale
\begin{equation*}
    L_{\bpi{}_{C}} \subseteq \left\{ 0,1 \right\}^{*} = \left\{ x \in \left\{ 0,1 \right\}^{*} : \bpi{}_{C}(x) = 1 \right\}
\end{equation*}

% TODO commento sui concreti e dipendenze pag 7.5
In questo modo lo spazio dei problemi è reso uniforme.

\subsubsection{Problema della codifica}
La complessità di un algoritmo è legata alla codifica scelta, infatti secondo il modello di costo di una \textit{Random Access Machine} in cui tutte le istruzioni hanno costo $1$:
\begin{equation}
    T_{A_{\bpi{}_{C}}} (n) = \max_{|x|=n} \left\{ \text{\# di passi impiegati da } A_{\bpi{}_{C}} (x) \right\}
    \label{eq:compltaglia}
\end{equation}
e in questa formula il parametro indipendente è la taglia dell'\textit{encoding}: $n=|e(i)|$

\subsubsection{Codifica dei numeri naturali positivi}
Si consideri l'insieme $\mathbb{N} - \left\{ 0 \right\}$ e un suo elemento generico $m$. Due codifiche possibili sono quella binaria e quella unaria.

Per la codifica binaria:
\begin{equation*}
    e_b (m) = <a_{k-1}, \cdots, a_0 > \quad \text{con} \quad k = \left\lfloor \log_2 m \right\rfloor + 1
\end{equation*}
e la lunghezza di un'istanza risulta logaritmica rispetto al valore
\begin{equation*}
    |e_b(m)| = \Theta \left( \log m \right)
\end{equation*}
In realtà la codifica è indipendente dalla base, varia solamente per una costante.

Per la codifica unaria:
\begin{equation*}
    e_u (m) = < \underbrace{1, \cdots, 1}_m >
\end{equation*}
e risultano istanze di lunghezza lineare rispetto al valore $m$
\begin{equation}
    |e_u(m)| = \Theta \left( m \right)
    \label{eq:coduncomp}
\end{equation}
ed esponenziale rispetto alla codifica binaria:
\begin{equation*}
    |e_u(m)| = \Theta \left( 2^{|e_b(m)|} \right)
\end{equation*}

Un semplice problema che evidenzia l'importanza della codifica è l'algoritmo che esegue la somma dei primi $m$ numeri interi:
\begin{algorithm}[H]
\caption{\textit{Gauss}}\label{alg:gauss}
\begin{algorithmic}[1]
    \Procedure{\textit{Gauss}}{$m$}
        \State $sum \gets 0$
        \For{$i \gets 1 $ to $ m $ }
            \State $sum \gets sum + i$
        \EndFor
        \State return $sum$
    \EndProcedure
\end{algorithmic}
\end{algorithm}
Per $m$ come valore, occorrono $\Theta \left( m \right)$ operazioni per concludere l'algoritmo.

Ricordando che la complessità va espressa in funzione della taglia dell'istanza, come indicato all'equazione \ref{eq:compltaglia}, le complessità risultano:

Nel caso della codifica unaria:
\begin{equation*}
    \Theta \left( m \right) = T_{G}^{u} \left( |<e_u(m)>| \right)
\end{equation*}
che componendo con l'equazione \ref{eq:coduncomp} risulta
\begin{equation*}
    T_{G}^{u} \left( n \right) = \Theta\left( n \right)
\end{equation*}
ossia una complessità lineare nel \textit{valore} dell'ingresso.

Per la codifica binaria
\begin{equation*}
    \Theta \left( m \right) = T_{G}^{b} \left( |<e_b(m)>| \right)
\end{equation*}
ma in questo caso il valore è legato in maniera esponenziale alla lunghezza dell'istanza
\begin{equation*}
    m = \Theta \left( 2^{|<e_b(m)>|} \right)
\end{equation*}
per cui risulta una complessità esponenziale dell'algoritmo, rispetto alla lunghezza della codifica dell'istanza
\begin{equation*}
    T_{G}^{b} \left( n \right) = \Theta \left( 2^n \right)
\end{equation*}

\section{Decisione in tempo polinomiale}
% pag 9.5

\section{Verifica in tempo polinomiale}
% pag 10

\section{Riducibilità}
% pag 12








\section{Pezzi utili di \LaTeX{}}
\begin{algorithm}[H]
\caption{Divide and Conquer}\label{alg:dnc}
\begin{algorithmic}[1]
    \Procedure{D\&C}{$i$}
        \If{$|i| \leq n_0$}
        \Comment{BASE}
            \State *risolvo direttamente*
        \EndIf
        \State $<i_1, i_2, \dots, i_k> \gets A_D(i)$ 
        \Comment{DIVIDE}
        \For{$j \gets 1 $ to $ k $ }
        \Comment{RECURSE}
            \State $s_j \gets $ \Call{D\&C}{$i_j$}
        \EndFor
        \State $s \gets A_C(<s_1, s_2, \dots, s_k>)$
        \Comment{CONQUER}
        \State return $s$
    \EndProcedure
\end{algorithmic}
\end{algorithm}


