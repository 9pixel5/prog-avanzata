\section{Ripasso}

Si ricordano le definizioni di algoritmo e problema computazionale astratto:

\begin{definition}[Algoritmo]\label{def:alg}
    Un algoritmo è una procedura computazionale finita (terminante) e deterministica, specificata come una sequenza di passi elementari (istruzioni) estratte da un insieme standard associato a un modello computazionale (astrazione di un computer) che trasforma in maniera univoca un ingresso in un uscita.
\end{definition}


\begin{definition}[Problema computazionale]\label{def:probcomp}
    Un problema computazionale $\bpi{}$ è una relazione tra un insieme di istanze $\bi{}$ e un insieme di soluzioni $\bs{}$: $\bpi{} \subseteq \bi{} \times \bs{}$
    \\
    Un problema computazionale definisce la specifica astratta. % ma de che?
\end{definition}

Note:
% \begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
\begin{itemize}[noitemsep,parsep=0pt,partopsep=0pt,topsep=0pt]
    \item[--] le seguenti notazioni sono usate in maniera equivalente: $i_1 \bpi{} s_1 \iff (i_1 , s_1 ) \in \bpi{}$
    \item[--] la relazione non è univoca, ad un'istanza possono essere associate più soluzioni
    \item[--] nella specifica astratta si assume esistano le soluzioni per ogni istanza:\\
        $\forall i \in \bi{},\exists s \in \bs{} | i \bpi{} s$
\end{itemize}

Un algoritmo $A_{\bpi{}}$ è un algoritmo per $\bpi{}$, ossia risolve $\bpi{}$ se, quando i suoi ingressi sono elementi di $\bi{}$, le sue uscite sono gli elementi di $\bs{}$ in relazione all'ingresso, formalmente:
$$ A: \bi{} \to \bs{} \quad \textrm{e} \quad A(i)=s \iff i \, \bpi{} \, s $$

\section{Categorie di problemi}
I problemi computazionali si possono dividere in quattro categorie:

\subsubsection{Polinomiali}
Problemi $\bpi{}$ che ammettono algoritmi di risoluzione polinomiale, che si possono considerare ``facili''. Si trova una certa evidenza epistemologica che i gradi in generale sono bassi, e si può considerare un problema polinomiale come trattabile.

\subsubsection{Con limite inferiore esponenziale}
Problemi $\bpi{}$ per cui si può provare che la complessità di ogni algoritmo che li risolve è esponenziale.
\begin{equation*}
    \forall A_{\bpi{}} \; \exists \, c > 1 : T_{A_{\bpi{}}} \left( n \right) = \Omega \left( c^{n} \right)
    % \label{}
\end{equation*}
I problemi per cui si riesce a dimostrare questa proprietà sono però molto pochi, in genere problemi artificiali legati ai linguaggi.

\subsubsection{Problemi che non ammettono algoritmi di risoluzione}
Ricordiamo che un algoritmo è una procedura \textit{terminante}. Per esempio l'\textit{halting problem}, si definisce come:
\begin{equation*}
    \bi{}_{H} = \left\{ <MT,x> \right\}
    \;\;
    \bs{}_{H} = \left\{ \texttt{Sì, No} \right\}
\end{equation*}

TODO mancano pezzi


\subsubsection{Problemi intrattabili}

Sono problemi per cui non esiste né un algoritmo $A_{\bpi{}}$ che li risolva, e neppure un \textit{lower bound} esponenziale.
Tuttavia c'è forte evidenza che il \textit{lower bound} esista, infatti si può provare che tutti i problemi in questa classe sono equivalenti, e questa proprietà di chiusura spinge verso la loro difficoltà.

\section{Problemi Decisionali}
% pag 4.2

\subsection{Problemi di ottimizzazione}
% pag 5

In un problema di ottimizzazione, si definisce una funzione di costo associato ad una soluzione:
\begin{equation*}
    c : \bs{} \to \mathbb{R}
\end{equation*}
e, dato l'insieme di soluzioni ammissibili associate ad un'istanza
\begin{equation*}
    \bs{} (i) = \left\{ s \in \bs{} : i \, \bpi{} \, s \right\}
\end{equation*}
si vuole individuare la soluzione di costo massimo (o minimo)
\begin{equation*}
    s_{i}^{*} = \argmax \left\{ c(s) : s \in \bs{} (i) \right\}
\end{equation*}

\subsection{Problemi Decisionali}
% pag 4.2

Per definire problemi e complessità degli algoritmi in modo rigoroso è necessario standardizzare i problemi computazionali.

Un problema decisionale presenta un insieme delle soluzioni ridotto a due elementi, ed associa ad un'istanza generica una risposta (positiva o negativa) ad una domanda sull'istanza.
\begin{equation*}
    \bpi{}_{D} : \bi{} \to \left\{ \texttt{Sì, No} \right\}
\end{equation*}

\subsubsection{\textit{Shortest Unweighted Path}}
% pag 4.5
% Il problema è definito sull'istanza $<G=(V,E), s, t>$, dove $V \subseteq \mathbb{N}$ finito (i nodi sono identificati con numeri naturali), $E \subseteq V \times V$ (gli archi sono coppie ordinate di vertici), $s, t \in V$. L'insieme delle soluzioni è $\mathbb{N}^*$, e una soluzione generica è $s=<v_1, \dots, v_k$, dove $v_i \in V, v_1=s, v_k=t$ e $\left( v_i, v_{i+1} \right) \in E, 1 \leq i < k$.
La restrizione ad un insieme binario di soluzioni non comporta una perdita di generalità, per esempio, si consideri il problema di trovare un cammino minimo tra due nodi in un grafo:
\begin{align*}
    \text{istanza:} \quad & <G=(V,E), s, t> \\
    \text{dove} \quad & V \subseteq \mathbb{N} \quad \text{finito (i nodi sono identificati con numeri naturali)} \\
    & E \subseteq V \times V \quad \text{(gli archi sono coppie ordinate di vertici)} \\
    & s, t \in V \\
    \text{soluzioni:} \quad & s=<v_1, \dots, v_k> \in \mathbb{N}^* \\
    i \, \bpi{} s \text{ se } \quad & 
    % \text{dove} \quad &
    v_i \in V \\
    & v_1=s, \: v_k=t \\
    & \left( v_i, v_{i+1} \right) \in E, 1 \leq i < k \\
    i \, \bpi{} \, \varepsilon \text{ se } \quad & \text{non esiste cammino tra $s$ e $t$ in $G$} \\
    \text{costo:} \quad & c\left( < v_1, \ldots, v_k > \right) = k-1 \\
    & c( \varepsilon ) = \infty \\
    \intertext{A questo problema di ottimizzazione si può associare un problema decisionale, arricchendo l'istanza con un limite superiore alla lunghezza del cammino}
    \text{istanza:} \quad & <G=(V,E), s, t, k> \\
    \text{domanda:} \quad & \text{esiste un cammino tra $s$ e $t$ in $G$, di lunghezza $\leq k$?} \\
\end{align*}
Avendo un algoritmo $A_{KUP}$ che risolva il problema decisionale, si può costruire facilmente un algoritmo che risolva $SUP$, usando $KUP$ come subroutine; l'algoritmo termina, perché si stanno cercando cammini semplici, quindi di lunghezza massima pari al numero di nodi meno uno.
\begin{algorithm}[H]
\caption{Shortest Unweighted Path}\label{alg:sup}
\begin{algorithmic}[1]
    \Procedure{$A_{SUP}$}{$<G=(V,E), s, t>$}
        \State $m \gets |V|$
        \For{$k \gets 0 $ to $ m-1 $ }
        \If{\Call{$A_{KUP}$}{$<G=(V,E), s, t, k>$} = \texttt{Sì}}
                \State return $k$
            \EndIf
        \EndFor
        \State return $\infty$
    \EndProcedure
\end{algorithmic}
\end{algorithm}
Per quanto riguarda la complessità, si possono considerare le due istanze come di taglia paragonabile
\begin{equation*}
    |<G, s, t, k>| = \Theta \left( |<G, s, t>| \right)
\end{equation*}
e assumendo $KUP$ polinomiale
\begin{equation*}
    T_{KUP} = O \left( |<G, s, t, k>|^{h} \right)
\end{equation*}
e considerando che il numero di archi è limitato dalla taglia dell'istanza
\begin{equation}
    m = O \left( |<G, s, t>| \right)
    \label{eq:tagliamgst}
\end{equation}
si ottiene che
\begin{align*}
    T_{SUP} \left( |<G, s, t>| \right) &= O \left( |<G, s, t>||<G, s, t>|^{h} \right) \\
    &= O \left( |<G, s, t>|^{h+1} \right)
\end{align*}
per cui se si riesce a risolvere il problema decisionale si può risolvere anche il problema di ottimizzazione.

Per ESERCIZIO, si scriva un algoritmo che ritorni anche il cammino minimo. Si suggerisce, dopo aver identificato $k$, di rimuovere archi per identificare quali siano quelli necessari per il cammino cercato. La complessità può risultare di due gradi superiore a quella di $KUP$.

\section{Codifica delle istanze}
% pag 6.7
Un problema astratto generico è definito quindi come
\begin{equation*}
    \bpi{}_{A} : \bi{} \to \left\{ \texttt{Sì, No} \right\}
\end{equation*}
Come si evidenzia nell'equazione \ref{eq:tagliamgst}, c'è un forte legame tra taglia dell'istanza e complessità dell'algoritmo. Va quindi definito precisamente il concetto di codifica di un'istanza.
\begin{definition}[\textit{Encoding} (codifica)]\label{def:codifica}
L'\textit{encoding} è una funzione invertibile (iniettiva)
\begin{equation*}
    e : \bi{} \to \setzo{*}
\end{equation*}
che mappa istanze in stringhe finite (quindi considera istanze numerabili, che è ragionevole). La notazione completa è $e_{\bi{}}$ per indicare che la codifica è legata ad un preciso insieme di istanze, ma il pedice viene omesso per leggibilità.
\end{definition}

Il problema astratto viene mappato nel problema concreto
\begin{equation*}
    \bpi{}_{C} : \setzo{*} \to \setzo{}
\end{equation*}
specificato come
\begin{equation*}
    \forall x \in \setzo{*} \quad
    \bpi{}_{C} (x) =
    \begin{cases}
        1 & \exists i \, \in \bi{} : e(i) = x \wedge \bpi{}_{A} (i) = \texttt{Sì} \\
        0 & \text{altrimenti}
    \end{cases}
\end{equation*}
Va notato che il problema concreto associa il valore $0$ sia ad istanze correttamente formate con risposta negativa, sia a tutte le stringhe non associate ad un'istanza.

Il problema concreto corrisponde ad un linguaggio formale
\begin{equation*}
    L_{\bpi{}_{C}} \subseteq \setzo{*} = \left\{ x \in \setzo{*} : \bpi{}_{C}(x) = 1 \right\}
\end{equation*}

% TODO commento sui concreti e dipendenze pag 7.5
In questo modo lo spazio dei problemi è reso uniforme.

\subsubsection{Problema della codifica}
La complessità di un algoritmo è legata alla codifica scelta, infatti secondo il modello di costo di una \textit{Random Access Machine} in cui tutte le istruzioni hanno costo $1$:
\begin{equation}
    T_{A_{\bpi{}_{C}}} (n) = \max_{|x|=n} \left\{ \text{\# di passi impiegati da } A_{\bpi{}_{C}} (x) \right\}
    \label{eq:compltaglia}
\end{equation}
e in questa formula il parametro indipendente è la taglia dell'\textit{encoding}: $n=|e(i)|$

\subsubsection{Codifica dei numeri naturali positivi}
Si consideri l'insieme $\mathbb{N} - \left\{ 0 \right\}$ e un suo elemento generico $m$. Due codifiche possibili sono quella binaria e quella unaria.

Per la codifica binaria:
\begin{equation*}
    e_b (m) = <a_{k-1}, \cdots, a_0 > \quad \text{con} \quad k = \left\lfloor \log_2 m \right\rfloor + 1
\end{equation*}
e la lunghezza di un'istanza risulta logaritmica rispetto al valore
\begin{equation*}
    |e_b(m)| = \Theta \left( \log m \right)
\end{equation*}
In realtà la codifica è indipendente dalla base, varia solamente per una costante.

Per la codifica unaria:
\begin{equation*}
    e_u (m) = < \underbrace{1, \cdots, 1}_m >
\end{equation*}
e risultano istanze di lunghezza lineare rispetto al valore $m$
\begin{equation}
    |e_u(m)| = \Theta \left( m \right)
    \label{eq:coduncomp}
\end{equation}
ed esponenziale rispetto alla codifica binaria:
\begin{equation*}
    |e_u(m)| = \Theta \left( 2^{|e_b(m)|} \right)
\end{equation*}

Un semplice problema che evidenzia l'importanza della codifica è l'algoritmo che esegue la somma dei primi $m$ numeri interi:
\begin{algorithm}[H]
\caption{\textit{Gauss}}\label{alg:gauss}
\begin{algorithmic}[1]
    \Procedure{\textit{Gauss}}{$m$}
        \State $sum \gets 0$
        \For{$i \gets 1 $ to $ m $ }
            \State $sum \gets sum + i$
        \EndFor
        \State return $sum$
    \EndProcedure
\end{algorithmic}
\end{algorithm}
Per $m$ come valore, occorrono $\Theta \left( m \right)$ operazioni per concludere l'algoritmo.

Ricordando che la complessità va espressa in funzione della taglia dell'istanza, come indicato all'equazione \ref{eq:compltaglia}, le complessità risultano:

Nel caso della codifica unaria:
\begin{equation*}
    \Theta \left( m \right) = T_{G}^{u} \left( |<e_u(m)>| \right)
\end{equation*}
che componendo con l'equazione \ref{eq:coduncomp} risulta
\begin{equation*}
    T_{G}^{u} \left( n \right) = \Theta\left( n \right)
\end{equation*}
ossia una complessità lineare nella taglia dell'istanza (che corrisponde al \textit{valore} dell'ingresso).

Per la codifica binaria
\begin{equation*}
    \Theta \left( m \right) = T_{G}^{b} \left( |<e_b(m)>| \right)
\end{equation*}
ma in questo caso il valore è legato in maniera esponenziale alla lunghezza dell'istanza
\begin{equation*}
    m = \Theta \left( 2^{|<e_b(m)>|} \right)
\end{equation*}
per cui risulta una complessità esponenziale dell'algoritmo, rispetto alla lunghezza della codifica dell'istanza
\begin{equation*}
    T_{G}^{b} \left( n \right) = \Theta \left( 2^n \right)
\end{equation*}

Come esempio numerico, si pensi alla differenza tra $1024$ e $10$, e come $2^{10}$ sia necessario per esprimere $1024$ in funzione di $10$.

La codifica unaria quindi maschera l'algoritmo come molto buono, nascondendo la complessità nella codifica stessa.

\begin{definition}[\textit{Encoding} conciso]
    \label{def:encodingconciso}
    Con le parentesi angolate $<\cdots>$ si indica l'uso di una codifica \textit{concisa} e \textit{ragionevole} dell'istanza.
\end{definition}


\section{Classi di problemi}

\subsection{Decisione in tempo polinomiale}
% pag 9.5

% MAYBE spostare questa definizione prima, dove introduce il legame linguaggio/algoritmo/problema
Considerando un problema $\bpi{}_{C}$ e un algoritmo $A_{\bpi{}_{C}}$ che risolve il problema, si dice che il linguaggio \textit{deciso} o \textit{accettato} da $A_{\bpi{}_{C}}$ è
\begin{equation*}
    L_{\bpi{}_{C}} = \left\{ x \in \setzo{*} : A_{\bpi{}_{C}}(x) = 1 \right\}
\end{equation*}
ossia l'insieme di stringhe per cui la computazione ha esito positivo.

\begin{definition}[Tempo polinomiale]
    \label{def:tempopoli}
    $L$ è deciso in tempo polinomiale se esiste un algoritmo $A$ tale che:
    % \begin{itemize}
    \begin{itemize}[itemsep=0pt]
    % \begin{itemize}[noitemsep,parsep=0pt,partopsep=0pt,topsep=0pt]
        \item[--] $L_A = L$ (il linguaggio deciso da $A$ è $L$)
        \item[--] $T_A(|x|) = O(|x|^k)$ per qualche costante $k \geq 0$
    \end{itemize}
\end{definition}

\begin{definition}[Classe $\bp$]
    \label{def:classep}
    La classe di problemi $\bp{}$ è l'insieme
    \begin{align*}
        \bp{} &= \left\{ L \subseteq \setzo{*} |\, L \text{ è deciso in tempo polinomiale}\right\} \\
        &= \left\{ \bpi{}_{C} : \setzo{*} \to \setzo{} |\, \bpi{}_C \text{ è risolto in tempo polinomiale} \right\}
    \end{align*}
\end{definition}


\subsection{Verifica in tempo polinomiale}
% pag 10

La classe $\bnp{}$ non viene caratterizzata utilizzando automi non deterministici, ma analizzando la complessità della \textit{verifica} della correttezza di una soluzione di un dato problema, senza preoccuparsi di come si è trovata questa soluzione.

Si consideri il problema di trovare un circuito \textit{Hamiltoniano} in un grafo non orientato:
\begin{align*}
    \text{istanza:} \quad & <G=(V,E)> \\
    \text{dove} \quad & G \text{ grafo non orientato} \\
    \text{domanda:} \quad & G \text{ contiene un ciclo semplice che tocca tutti i nodi?} \\
    \text{soluzioni:} \quad & s=<v_1, \dots, v_k> \in \mathbb{N}^* \\
    i \, \bpi{} s \text{ se } \quad & 
    % \text{dove} \quad &
    v_i \in V \\
    & v_1 = v_k \\
    & \left( v_i, v_{i+1} \right) \in E, 1 \leq i < k \\
    & v_i \neq v_j , 1 \leq i < j < k
\end{align*}
In questo caso la soluzione è difficile da trovare, ma verificare se un cammino sia valido è facile, infatti:
\begin{algorithm}[H]
\caption{Verificatore per Hamiltonian}\label{alg:verifyh}
\begin{algorithmic}[1]
    \Procedure{VERIFY\_H}{$x, y$}
        \If{$x \neq <G=(V,E)>$}
        \Comment{verifico $x$ sia istanza ben formata}
            \State return $0$
        \EndIf
        \If{$x \neq <v_1, v_2, \cdots, v_{|V|+1}>$}
        \Comment{verifico $y$ codifichi un cammino valido }
            \State return $0$
        \EndIf
        \If{$ v_1 \neq v_{|V|+1}$}
        \Comment{che sia un ciclo}
            \State return $0$
        \EndIf
        \If{* $ \exists i,j : 1 \leq i < j < |V| : v_i \neq v_j $ * }
        \Comment{che sia semplice}
            \State return $0$
        \EndIf
        \For{$i \gets 1 $ to $ |V| $ }
        % \Comment{}
            \If{$ ( v_i , v_{i+1} ) \notin E $  }
                \State return $0$
            \EndIf
        \EndFor
        \State return $1$
    \EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{definition}[Verificatore, certificato]
    \label{def:verificatore}
    $V(x,y)$ verifica $\bar{x}$ se 
    \begin{equation*}
    % $
        \exists \bar{y} : V( \bar{x}, \bar{y}) = 1
    \end{equation*}
    % $
    $\bar{y}$ si dice \textit{certificato} per $\bar{x}$
\end{definition}

\begin{definition}[Linguaggio verificato]
    \label{def:linguaggioverificato}
    Il linguaggio verificato da $V(x,y)$ è
    \begin{equation*}
        L_V = \left\{ \bar{x} \in \setzo{*} \text{ verificate da } V(x,y) \right\}
    \end{equation*}
\end{definition}

\begin{definition}[Verifica polinomiale]
    \label{def:verificapolinomiale}
    $L$ è un linguaggio verificato in tempo polinomiale se
    \begin{itemize}
        \item $ \exists \, V_L (x,y) : L_{V_{L}} = L$
        \item $ \forall x \in L, \; \exists y : V_L(x,y) = 1 \wedge |y| = O \left( |x|^{k_{1}} \right) $ per qualche $k_1 \geq 0$ costante (il certificato non può essere troppo esteso rispetto all'istanza)
        \item $ T_{V_{L}} (|x|, |y|) = O \left( \left( |x|+|y| \right)^{k_{2}} \right)$ per qualche $k_2 \geq 0$ costante (tempo del verificatore polinomiale negli ingressi)
    \end{itemize}
\end{definition}

\begin{definition}
    \label{def:classenp}
    La classe di problemi $\bnp{}$ è l'insieme
    \begin{equation*}
        \bnp{} = \left\{ L \subseteq \setzo{*} \to \setzo{} |\, L \text{ è verificato in tempo polinomiale}\right\}
    \end{equation*}
\end{definition}

% \section{$\bp{}$ \textit{vs} $\bnp{}$}
\subsection{P vs NP}
\label{sss:pvsnp}
% pag 11.8

La domanda del millennio è la seguente:
\begin{equation*}
    \bp{} = \bnp{}
    \quad
    \texttt{vs}
    \quad
    \bp{} \neq \bnp{}
\end{equation*}

È facile provare che $\bp{} \subseteq \bnp{}$, ossia che $\forall L \in \bp{}$ ammette un verificatore polinomiale. Infatti, se $L \in \bp{}, \exists A_{L}(x) : x \in L \Leftrightarrow A_L (x) = 1$ e in più $T_{A_{L}} (|x|) = O \left( |x|^{k} \right)$ per cui è triviale esibire un verificatore per $L$
\begin{algorithm}[H]
    \caption{Verificatore per $L$ in $\bp{}$}\label{alg:verificap}
\begin{algorithmic}[1]
    \Procedure{V\_L}{$x,y$}
        \State return $A_L (x)$
    \EndProcedure
\end{algorithmic}
\end{algorithm}

Sotto l'ipotesi $\bp{} \neq \bnp{} $, si trova una classe di linguaggi $\bnpc{} \subseteq \bp{} - \bnp{} $ detti NP-completi. Si può costruire una relazione d'ordine tra linguaggi, e provare che gli $\bnpc{}$ sono i $\sup$ di questa relazione, e sono tutti equivalenti. Se uno di questi appartenesse a $\bp{}$, l'intera classe collasserebbe in $\bp{}$.


\section{Riducibilità}
% pag 12

Dati due problemi
$\bpi{}_1$
e
$\bpi{}_2$
, si cerca una funzione $f$ in modo che la soluzione di $f(i_1)$ implichi la soluzione di $i_1$.
\begin{itemize}[noitemsep,parsep=0pt,partopsep=0pt,topsep=0pt]
    \item se $i_1$ è positiva $\Rightarrow i_2 = f(i_1)$ è positiva
    \item se $i_1$ è negativa $\Rightarrow i_2 = f(i_1)$ è negativa
\end{itemize}
Ossia $i_1$ è positiva $\Leftrightarrow i_2 = f(i_1)$ è positiva.

Per rispondere a $\bpi{}_1$ si usa la risposta a $\bpi{}_2$, da cui si intuisce che è il secondo problema il più difficile (sapere 1 non dice nulla su 2):
\begin{equation*}
\bpi{}_1
\lp
% \bpi{}_2
\bpi_2
\end{equation*}

Si consideri di nuovo il problema di \textit{Hamilton} e la sua relazione con il \textit{Travelling Salesman Problem}:
\begin{align*}
    \text{Hamilton:} & \quad \\
    \text{istanza:} \quad & <G=(V,E)> \\
    \text{domanda:} \quad & G \text{ contiene un ciclo semplice che tocca tutti i nodi?} \\
    \text{TSP:} & \quad \\
    \text{istanza:} \quad & <G_C=(V,E_C), w, k> \\
    \text{dove} \quad & G_C \text{ grafo completo non orientato} \\
    & w : E \to \mathbb{N} - \left\{ 0 \right\} \\
    & k \in \mathbb{N} \\
    \text{domanda:} \quad & G \text{ contiene un ciclo \textit{Hamiltoniano} di costo $\leq k$?} \\
    \text{dove} \quad &  c(<v_1, \cdots, v_{|V|+1}>) = \sum_{i=1}^{|V|} w(v_i, v_{i+1} )  \\
\end{align*}
Dall'istanza di \textit{Hamilton} generica 
$i_1 = <G=(V,E)>$
si ottiene con facilità l'istanza del \textit{Travelling Salesman Problem}
$i_2 = <G_C=(V,E_C), w, k>$

\begin{itemize}[parsep=0pt,partopsep=0pt,topsep=2pt]
    \item[--] si aggiungono archi come necessario per rendere completo il grafo
    \item[--] $w(e) = 
        \begin{cases}
            1 & e \in E \\
            2 & e \in E_C - E
        \end{cases}
        $
    \item[--] $k = |V|$
\end{itemize}
In questo modo, se $G$ è \textit{Hamiltoniano}, esiste un ciclo di costo $|V|$ e TSP risponde \texttt{Sì}. Se invece serve un arco in $E_C - E$, il costo salirebbe, andando oltre $k$.

\begin{definition}[Calcolabile in tempo polinomiale]
    \label{def:calcolabilepolinomiale}
    La funzione
    \begin{equation*}
        f : \setzo{*} \to \setzo{*} 
    \end{equation*}
    si dice calcolabile in tempo polinomiale se esiste un algoritmo $A_F (x)$ che la calcola, per cui vale, per qualche $k \geq 0$ costante
    \begin{equation*}
        T_{A_{F}} (|x|) = O \left( |x|^{k} \right)
    \end{equation*}
\end{definition}

\begin{definition}[Riducibilità]
    \label{def:riducibilita}
    Il linguaggio $L_1$ si riduce al linguaggio $L_2$
    \begin{equation*}
        L_1 \lp L_2
    \end{equation*}
    se esiste $f(x)$ calcolabile in tempo polinomiale per cui
    \begin{equation*}
        x \in L_1 \Leftrightarrow f(x) \in L_2
    \end{equation*}
    ossia
    \begin{equation*}
        \bpi_{L_{1}} (x) = \texttt{Sì}
        \Leftrightarrow
        \bpi_{L_{2}} \left( f\left( x \right) \right) = \texttt{Sì}
    \end{equation*}
\end{definition}
Note: 
\begin{itemize}[noitemsep,parsep=0pt,partopsep=0pt,topsep=0pt]
    \item $f$ \textit{deve} essere calcolabile in tempo polinomiale.
    \item tutto $L_1$ deve essere mappato in $L_2$
    \item tutto il complementare di $L_1$ deve essere mappato nel complementare di $L_2$
\end{itemize}
% TODO disegno 13.8
L'immagine nel caso più estremo può anche essere di due soli punti, tutta la complessità in questo caso è annidata in $f$.

\begin{theorem}[Relazione d'ordine]
    \label{teo:relazioneordine}
    Siano $L_1, L_2 \subseteq \setzo{*}$, la relazione d'ordine fra linguaggi è indicata da
    \begin{equation*}
        \left( L_1 \lp L_2 \right) \wedge \left( L_2 \in \bp \right) \Rightarrow L_1 \in \bp
    \end{equation*}
\end{theorem}

\begin{proof}
    La prima ipotesi $\left( L_1 \lp L_2 \right)$ implica che esiste una funzione $f(x)$ calcolabile in tempo polinomiale per cui $x \in L_1 \Leftrightarrow f(x) \in L_2 $ e $ T_{A_{f}} (|x|) = O \left( |x|^{k_1} \right) $ \\
    La seconda ipotesi $ \left( L_2 \in \bp \right) $ implica l'esistenza di un algoritmo $A_{L_{2}}(x)$ che decide $L_2$, con $ T_{A_{L_{2}}} (|x|) = O \left( |x|^{k_2} \right) $ \\
    Allora è sufficiente esibire il decisore per $L_1$, che compone riduzione e decisione, dimostrando che è effettivamente un decisore per $L_1$, ed è polinomiale.
\begin{algorithm}[H]
\caption{Decisore per $L_1$}\label{alg:decisorel1}
\begin{algorithmic}[1]
    \Procedure{A\_L1}{$x$}
    \State return $A_{L_2}\left( A_{f} \left( x \right) \right)$
    \EndProcedure
\end{algorithmic}
\end{algorithm}
    Per quanto riguarda la polinomialità dell'algoritmo, la complessità risulta composta da due parti, la prima dovuta all'invocazione di $A_f$, la seconda dovuta alla chiamata di $A_{L_2}$ su $f(x)$:
    \begin{equation*}
        T_{A_{L_{1}}}(|x|) = O \left( |x|^{k_1} \right) + O \left( \left( |x|^{k_1} \right)^{k_2} \right)
    \end{equation*}
    Definendo $k_3 = \max \left\{ k_1, k_1 \cdot k_2 \right\}$, dato che $k_2$ può essere minore di $0$, risulta
    \begin{equation*}
        T_{A_{L_{1}}}(|x|) = O \left( |x|^{k_3} \right) 
    \end{equation*}
    Per dimostrare che il linguaggio deciso da quest'algoritmo sia proprio $L_1$, si seguono due catene di implicazioni:
    \begin{equation*}
        x \in L_1 
        \Rightarrow
        f(x) \in L_2 
        \Rightarrow
        A_{L_2}\left( f(x) \right) = 1
        \Rightarrow
        A_{L_1} (x) = 1
    \end{equation*}
    \begin{equation*}
        x \notin L_1 
        \Rightarrow
        f(x) \notin L_2 
        \Rightarrow
        A_{L_2}\left( f(x) \right) = 0
        \Rightarrow
        A_{L_1} (x) = 0
    \end{equation*}
\end{proof}

\subsubsection{Proprietà della relazione tra linguaggi}
\begin{itemize}
    \item $\lp$ è riflessiva: $L \lp L$, e $f$ è l'identità
    \item $\lp$ è transitiva: $(L_1 \lp L_2) \wedge (L_2 \lp L_3) \Rightarrow (L_1 \lp L_3)$, la composizione di due funzioni polinomiali è polinomiale
\end{itemize}

\begin{definition}[NP-hard]
    \label{def:nphard}
    Un linguaggio $L \subseteq \setzo{*}$ si dice NP-hard se
    \begin{equation*}
        \forall L' \in \bnp \quad \to \quad L' \lp L
    \end{equation*}
\end{definition}

\begin{definition}[NP-completo]
    \label{def:npcompleto}
    Un linguaggio $L \subseteq \setzo{*}$ si dice NP-completo se
    \begin{align*}
        L & \in \bnp \\
        L & \in \bnph
    \end{align*}
    I problemi NP-completi sono i più difficili \textit{nella} classe $\bnp$
\end{definition}

\begin{corollario}[P=NP]
    Se esistesse un linguaggio NP-completo in $\bp$ le classi $\bp, \bnp$ sarebbero equivalenti
    \begin{equation*}
        \exists L \in \left( \bnpc \cap \bp \right)
        \quad
        \Rightarrow
        \quad
        \bp = \bnp
    \end{equation*}
\end{corollario}
\begin{proof}
    La tesi equivale a $ ( \bp \subseteq \bnp ) \wedge ( \bnp \subseteq \bp )$
    La prima parte è già stata vista alla sezione \ref{sss:pvsnp}. Per la seconda, si consideri un generico $L' \in \bnp$. Vale $L' \lp L$ perché $L \in \bnpc$ e tutti i linguaggi in $\bnp$ si riducono ad esso, e per ipotesi $L \in \bp$. Per il teorema \ref{teo:relazioneordine} vale quindi
    \begin{equation*}
        \left( L' \lp L \right) \wedge \left( L \in \bp \right) \Rightarrow   L \in \bp 
    \end{equation*}
\end{proof}

La teoria della complessità strutturale studia, sotto l'ipotesi $\bp \ne \bnp$, che tipologie di problemi intermedi siano esistenti, e si può costruire un'intera gerarchia infinita di complessità dei problemi.

\section{Problemi NP-completi}

Dimostrare che un problema è NP-completo non è semplice, vanno infatti provate due proprietà per verificare che $L \in \bnpc$:
\begin{enumerate}
    \item $L \in \bnp$
    \item $\forall L' \in \bnp, L' \lp L$
\end{enumerate}
La prima è ragionevole, ed è sufficiente esibire un verificatore $V_L(x,y)$. La seconda invece è estremamente pesante, perché è necessaria una catena infinita di riduzioni per provare che \textit{per ogni} $L'$ la relazione sia verificata.

Si procede quindi in modo diverso: supponendo che un linguaggio \textit{sia} in $\bnpc$, è sufficiente una singola riduzione per provare che il linguaggio candidato sia NP-completo.

Ovvero, se $\bar{L} \in \bnpc$, vale $L_C \in \bnpc$?

Se si dimostra la riduzione
$
\bar{L} \lp L_C
$
si può applicare la proprietà transitiva della relazione $\lp$ per cui
\begin{equation*}
    \left( L' \lp \bar{L} \right) \wedge \left( \bar{L} \lp L_C \right) \Rightarrow  L' \lp L_C
\end{equation*}

\subsection{Circuiti \textit{booleani}}

Un circuito \textit{booleano}, o circuito combinatorio, è un'interconnessione di gate \textit{senza cicli}, in cui l'output di un gate può essere input di uno o più gate. I fili che non provengono da gate sono gli input del circuito, e i fili che non entrano in gate sono gli output del circuito. Verranno considerati solo circuiti con un singolo output.

Il circuito si può scrivere come funzione $C \left( x_1, \cdots, x_k \right)$, ed è isomorfo al grafo in cui i fili corrispondono ad archi, e vengono aggiunti nodi per input e output del circuito:
\begin{equation*}
    C \equiv G_C = \left( I \cup G \cup \left\{ o \right\}, W \right)
\end{equation*}

Si indica con \textit{fan-in} il massimo numero di ingressi ad un gate, e con \textit{fan-out} il massimo numero di gate raggiuni da un output di un gate.

Assegnando dei valori di verità $\vec{b} \in \setzo{k}$ agli input di un circuito, si dice che questo \textit{commuta}, ossia assume una certa configurazione di valori su ogni filo, che si indica
\begin{equation*}
    Config(C) = \vec{h} \in \setzo{m}
\end{equation*}

Un circuito di dice \textit{soddisfacibile} se
\begin{equation*}
    \exists \,\vec{b} \in \setzo{k} : C ( \, \vec{b} \,) = 1
\end{equation*}

Il problema di stabilire la soddisfacibilità di un circuito è stato risolto da $Cook$ nel 1971, ed è stato dimostrato essere NP-completo.
\begin{align*}
    \text{istanza:} \quad & < C \left( x_1, \cdots, x_k \right) > \\
    \text{domanda:} \quad & C \text{ è soddisfacibile?}
\end{align*}

Un verificatore per il problema è semplice da implementare, e risulta lineare nella taglia del circuito:
\begin{algorithm}[H]
\caption{Soddisfacibilità di un circuito}\label{alg:cooksoddisfa}
\begin{algorithmic}[1]
    \Procedure{VERIFY\_BC\_SAT}{$x,y$}
        \State * controllare se $x = < I \cup G \cup \left\{ o \right\}, W >$ è aciclico *
        \State * controllare se $y = < W_1, \cdots, W_{|W|}$ corrisponde ad un valore per filo *
        \State * controlla la validità della configurazione, per ogni gate in $G$ l'output del gate deve implementare la funzione correttamente *
        \State * controlla se il valore di uscita è uno: $W_o = 1$*
    \EndProcedure
\end{algorithmic}
\end{algorithm}



\section{Pezzi utili di \LaTeX{}}
\begin{algorithm}[H]
\caption{Divide and Conquer}\label{alg:dnc}
\begin{algorithmic}[1]
    \Procedure{D\&C}{$i$}
        \If{$|i| \leq n_0$}
        \Comment{BASE}
            \State *risolvo direttamente*
        \EndIf
        \State $<i_1, i_2, \dots, i_k> \gets A_D(i)$ 
        \Comment{DIVIDE}
        \For{$j \gets 1 $ to $ k $ }
        \Comment{RECURSE}
            \State $s_j \gets $ \Call{D\&C}{$i_j$}
        \EndFor
        \State $s \gets A_C(<s_1, s_2, \dots, s_k>)$
        \Comment{CONQUER}
        \State return $s$
    \EndProcedure
\end{algorithmic}
\end{algorithm}


\begin{definition}[Algoritmo]\label{def:algex}
    Un algoritmo è una procedura computazionale finita (terminante) e deterministica, specificata come una sequenza di passi elementari (istruzioni) estratte da un insieme standard associato a un modello computazionale (astrazione di un computer) che trasforma in maniera univoca un ingresso in un uscita.
\end{definition}

Look here 
\begin{equation*}
    \setzo{m}
    \quad
    \setzo{}
\end{equation*}

\begin{itemize}[noitemsep,parsep=0pt,partopsep=0pt,topsep=0pt]
    \item[--] $L_A = L$ (il linguaggio deciso da $A$ è $L$)
    \item[--] $T_A(|x|) = O(|x|^k)$ per qualche costante $k \geq 0$
\end{itemize}
